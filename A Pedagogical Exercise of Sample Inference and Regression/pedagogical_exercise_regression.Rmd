---
title: "A Pedagogical Exercise in Regression"
output: 
   html_document:
    toc: yes
    toc_depth: 3
    css: ../style.css
params:
  date: !r Sys.Date()
---

```{r,setup, include=FALSE, eval=TRUE}
options(knitr.table.format = "html", width = 140)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, fig.width = 12, fig.height = 9)
```

<div>Author: Rick Dean</div>
<div>Article date: `r params$date`</div>

<div class="abstract">
  <p class="abstract">Abstract</p>
  The following are notes and R scripts inspired by the article [What Do We Know About British Attitudes Toward Immigration? A Pedagogical Exercise of Sample Inference and Regression](http://svmiller.com/blog/2020/03/what-explains-british-attitudes-toward-immigration-a-pedagogical-example/) by Steve Miller.
</div>

```{r, warning=FALSE, message=FALSE}
library(knitr)
library(here)
library(data.table)
library(kableExtra)
library(RplotterPkg)
library(RregressPkg)
library(ggplot2)
```

## Prepare the data
Read the data frame from the European Social Survey of about 2,000 residents of the United Kingdom and convert to a `data.table`:
```{r}
current_dir <- here::here()
data_path <- file.path(current_dir, "A Pedagogical Exercise of Sample Inference and Regression/data/ESS9GB.rda")
load(data_path)
data_dt <- data.table::setDT(ESS9GB)
```
Filter for just British respondents born in the UK:
```{r}
data_dt <- data_dt[cntry == "GB" & brncntr == 1]
```

Select and rename a subset of the available variables for later regression:
```{r}
data_dt <- data_dt[, .(
  ImmigSentiment = immigsent,
  Age = agea,
  Female =female,
  YrsEdu =eduyrs,
  UnEmploy = uempla,
  HouseIncome = hinctnta,
  Ideology = lrscale,
  Region = as.factor(region)
)]
head(data_dt)
```

## Look at the data

1. Complete a statistical summary of the dependent variable *ImmigSentiment*:
```{r}
summary_dt <- data_dt[, .(
    mean = round(mean(ImmigSentiment, na.rm = T), 3),
    median = round(median(ImmigSentiment, na.rm = T), 3),
    sd = round(sd(ImmigSentiment, na.rm = T), 3),
    min = round(min(ImmigSentiment, na.rm = T), 3),
    max = round(max(ImmigSentiment, na.rm = T), 3),
    n = sum(!is.na(ImmigSentiment)),
    missing = sum(is.na(ImmigSentiment))
)]
RplotterPkg::create_table( 
  x = summary_dt,
  col_names = c("Mean", "Median", "SD", "Minimum", "Maximum", "N", "Miss Responses"),
  caption = "Summary of dependent variable ImmigSentiment",
  position = "center",
  head_bkgd = "purple",
  head_col = "white",
  align_v = rep("c",7)
)
```


2. Plot a histogram of the dependent variable *ImmigSentiment*:
```{r, fig.width=14}
RplotterPkg::create_histogram_plot(
  df = data_dt,
  aes_x = "ImmigSentiment",
  title = "A Bar Chart of Pro-Immigration Sentiment",
  subtitle = "Data: European Social Survey, Round 9 in the United Kingdom",
  x_title = "Pro-Immigration Sentiment Value",
  y_title = "Number of Respondents",
  binwidth = 1,
  x_major_breaks = seq(0,30,1),
  bar_fill = "blue",
  bar_color = "white",
  bar_labels = T,
  show_minor_grids = F
)
```

<div class="takeaway">Take Away: There appears to be a heaping of 0's and 30's.</div><br>

## The true population mean

<blockquote class="quo">
...central limit theorem says that infinite random samples of any size of a population will produce sample means that follow a normal distribution. 

...the inferences we make are less about saying what the “true” population mean is -- it’s more about “ruling out” other alternatives as highly unlikely, given what we know from central limit theorem and the properties of a normal distribution.
</blockquote>

Take smaller samples of the population (i.e. group by region) and compare their means to the overall estimate of the population mean of 16.891:

```{r}
region_sentiment_dt <- data_dt[, .(sent_mean = round(mean(ImmigSentiment, na.rm = T), 3)), by = Region][order(-sent_mean)]
RplotterPkg::create_table(
  x = region_sentiment_dt,
  col_names = c("Region","Average Pro-Immigration Sentiment"),
  caption = "Average Pro-Immigratioin Sentiment in the United Kingdom, by Region, in the ESS (2018-19)",
  head_bkgd = "purple",
  head_col = "white",
  position = "center",
  align_v = c("l","c")
)
```

To compare the above regional means, compute the standard error of the estimated overall population mean and its 95% confidence interval.

<blockquote>This is the interval through which 95% of all possible sample means would fall by chance, given what we know about the normal distribution</blockquote>

```{r}
sent_n <- nrow(na.omit(data_dt))
sent_mean <- round(mean(data_dt$ImmigSentiment, na.rm=T), 3)
sent_sd <- round(sd(data_dt$ImmigSentiment, na.rm=T), 3)
sent_se <- round(sent_sd/sqrt(nrow(data_dt)), 3)
sent_se_dt <- data.table(
  N = sent_n,
  mean = sent_mean,
  se = sent_se,
  lb95 = round(sent_mean - 1.96 * sent_se, 3),
  ub95 = round(sent_mean + 1.96 * sent_se, 3)
)
RplotterPkg::create_table(
  x = sent_se_dt,
  col_names = c("Sample N", "Sample Mean", "SE Sample Mean", "95% Lower CI", "95% Upper CI"),
  caption = "Average Pro-Immigration Sentiment and Its 95% Confidence Interval",
  head_bkgd = "purple",
  head_col = "white",
  position = "center",
  align_v = rep("c",5)
)
```

<div class="takeaway">Take Away: ...if we took 100 samples of this size (n = 1,454), 95 of those random samples would, on average, have sample means between about 16.577 and 17.205.</div><br>

If we have a proposed population mean of 14.65, compute the number of standard deviations the proposed mean is from our estimated population mean of 16.891. We can answer this question by computing the z-score which is the difference between the proposed and sample means divided by the standard error of the sample mean.

```{r}
z_sent_dt <- data.table(
  mean = sent_mean,
  proposed_mean = 14.65,
  se = sent_se,
  zscore = round((sent_mean - 14.65)/sent_se, 3)
)
RplotterPkg::create_table(
  x = z_sent_dt,
  col_names = c("Sample Mean", "Proposed Mean", "SE of Sample Mean", "z-score"),
  caption = "How Unlikely Was the Proposed Mean",
  head_bkgd = "purple",
  head_col = "white",
  position = "center",
  align_v = rep("c",4)
)
```

<div class="takeaway">Take Away: The proposed mean of 14.65 is about 14 standard errors away from the sample mean.</div><br>

<blockquote>...we are not saying the true population mean is actually our sample mean. The true population mean in this context is ultimately unknowable, but inference in this context comes not in saying what “is” but in ruling out things as highly unlikely to be true. </blockquote>

## Regression as more inference by "Ruling Things Out"
Set up a regression of immigration sentiment with the following linear model:

$$ImmSentiment_{i} = \beta_{0}+\beta_{1}*Age_{i}+\beta_{2}*Female_{i}+\beta_{3}*Years Ed_{i}+\beta_{4}*Unemployed_{i}+\beta_{5}*HouseholdInc_{i}+\beta_{6}*Ideology_{i}+\epsilon_{i}$$

```{r}
ols_sent_lst <- RregressPkg::ols_calc(
  df = data_dt,
  formula_obj = ImmigSentiment ~ Age + Female + YrsEdu + UnEmploy + HouseIncome + Ideology,
  na_omit = T
)
RplotterPkg::create_table(
  x = ols_sent_lst$coef_df,
  caption = "ImmigSentiment ~ Age + Female + YrsEdu + UnEmploy + HouseIncome + Ideology",
  head_bkgd = "purple",
  head_col = "white",
  position = "center",
  align_v = c("l", rep("c",4))
)
```

<div class="takeaway">Take Away: Higher levels of education coincide with an increase in pro-immigration sentiment -- a positive coefficient and relationship.  Those with an ideology closer to the right have lower levels of pro-immigration sentiment -- a negative coefficient and relationship.</div><br>

<div class="takeaway">Take Away: As Steve Miller points out, the `(Intercept)` value is totally useless.</div><br>


The $R^2$ = `r ols_sent_lst$rsquared`

## Refine the regression by standardizing the non-binary predictors
```{r}
r2sd <- function(x, na = T) {
    return((x - mean(x, na.rm = na)) / (2 * sd(x, na.rm = na)))
}

data_stand_dt <- data_dt[, .(
  ImmigSentiment = ImmigSentiment, 
  Age = r2sd(Age),
  Female = Female,
  YrsEdu = r2sd(YrsEdu),
  UnEmploy = UnEmploy,
  HouseIncome = r2sd(HouseIncome),
  Ideology = r2sd(Ideology)
)]

ols_stand_sent_lst <- RregressPkg::ols_calc(
  df = data_stand_dt,
  formula_obj = ImmigSentiment ~ Age + Female + YrsEdu + UnEmploy + HouseIncome + Ideology,
  na_omit = T
)

RplotterPkg::create_table(
  x = ols_stand_sent_lst$coef_df,
  caption = "ImmigSentiment ~ Age + Female + YrsEdu + UnEmploy + HouseIncome + Ideology",
  head_bkgd = "purple",
  head_col = "white",
  position = "center",
  align_v = c("l", rep("c",4))
)
```

<div class="takeaway">Take Away: As Steve Miller states:</div><br>

<blockquote>When standardized, the 17.269 gives us the estimated value for an employed man of average age, education, income, and ideology. That y-intercept is much more useful the extent to which it conveys a quantity of interest for an observation that is much more likely to actually exist.</blockquote>

<div class="takeaway">Take Away: *YrsEdu* has the strongest magnitude effect and the most precise.  *HouseIncome* and *Ideology* look more comparable in the standandized vs unstandandized.</div><br>

## Constant variance for OLS residuals?

Performing the Breusch-Pagan test for Heteroskedasticity:

```{r}
bp_test_df <- RregressPkg::ols_BP_test_calc(
  df = data_stand_dt,
  formula_obj = ImmigSentiment ~ Age + Female + YrsEdu + UnEmploy + HouseIncome + Ideology
)

RplotterPkg::create_table(
  x = bp_test_df,
  caption = "BP Homoskedasticity Test",
  head_bkgd = "purple",
  head_col = "white",
  position = "center"
)
```

The null hypothesis is that homoskedasticity holds and that the variance of the residuals $\mu_{i}$ are constant and uncorrelated with the predictors:
$$H_{0}: Var(\mu|x_{1}, x_{2}...x_{k}) = \sigma^2$$

<div class="takeaway">Take Away: It appears that with the small $p$-values the standard errors reported above may not be reliable and some transformation of the data may be necessary.</div><br>

## Plot residuals versus fitted values
```{r}
resid_fit_dt <- data.table(
  Fit = ols_stand_sent_lst$fitted_vals,
  Residuals = ols_stand_sent_lst$residual_vals
)
RplotterPkg::create_scatter_plot(
  df = resid_fit_dt,
  aes_x = "Fit",
  aes_y = "Residuals",
  rot_y_tic_label = T
)
```

<div class="takeaway">Take Away: The residuals do not appear to be random about zero, but show a definite pattern.</div><br>
