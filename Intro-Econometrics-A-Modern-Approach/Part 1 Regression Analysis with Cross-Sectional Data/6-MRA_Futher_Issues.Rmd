---
title: "6-MRA_Further Issues"
output: 
   html_document:
    toc: yes
    toc_depth: 3
    css: ../../style.css
params:
  date: !r Sys.Date()    
---

```{r,setup, include=FALSE, eval=TRUE}
options(knitr.table.format = "html", width = 140)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, fig.width = 12, fig.height = 8)
```

<div>

Author: Rick Dean

</div>

<div>

Article date: `r params$date`

</div>

::: {.abstract}
<p class="abstract">

Abstract

</p>

The following notes and scripts are based on the following sources: [Introductory Econometrics - A Modern Approach](https://www.amazon.com/Introductory-Econometrics-Modern-Approach-Standalone/dp/130527010X/ref=sr_1_2?dchild=1&keywords=Introductory+Econometrics%3A+A+Modern+Approach&qid=1597005903&s=books&sr=1-2) by Jeffrey M. Wooldridge is the main text for the statistical content. This text will be referenced as `(Wooldridge)`.

The companion text [Using R for Introductory Econometrics](http://www.urfie.net/index.html) by Florian Heiss provides specific R scripts in support of the main text and the inspiration for my scripts, notes and graphics. I will reference this document as `(Heiss)`. The following is from **Part 1 - Regression Analysis with Cross-Sectional Data, Chapter 6 MRA Further Issues** of `(Heiss)`.
:::

```{r, warning=FALSE, message=FALSE}
library(knitr)
library(kableExtra)
library(data.table)
library(wooldridge)
library(ggplot2)
library(RregressPkg)
library(RplotterPkg)
```

# 6 Multiple Regression Analysis: Further Issues

## 6.1 Model Formulae

## 6.2 Prediction

Predicting the value of the response variable $y$ given certain values of the predictors $x_{1}, x_{2} ... x_{k}$.

::: {.note}
Note: In this section we will be following `(Wooldridge page 186 Sectiion 6-4)` to incorporate his techniques rather than using `stats::predict()` from R.
:::

### 6.2.1 Confidence intervals for predictions

Given a OLS model:

<center>

$\hat{y} = \hat{\beta_{0}} + \hat{\beta_{1}}x_{1} + \hat{\beta_{2}}x_{2} + ... \hat{\beta_{k}}x_{k}$[[6.27]]{style="float:right;"}

</center>

and specific values for the predictors: $c_{1}, c_{2} ... c_{k}$

We want to measure the uncertainty for the predicted value $\hat{\theta_{0}}$ where:

<center>

$\hat{\theta_{0}} = \hat{\beta_{0}} + \hat{\beta_{1}}c_{1} + \hat{\beta_{2}}c_{2} + ... \hat{\beta_{k}}c_{k}$[[6.29]]{style="float:right;"}

</center>

A `[Wooldridge]` trick is described for estimating a standard error and subsequently a confidence interval for $\hat{\theta_{0}}$ by solving for the intercept $\hat{\beta_{0}}$ in equation [6.29] and plugging it into equation [6.27] to obtain:

<center>

$y = \hat{\theta_{0}} + \beta_{1}(x_{1} - c_{1}) + \beta_{2}(x_{2} - c_{2}) + ... + \beta_{k}(x_{k} - c_{k})$[[6.30]]{style="float:right;"}

</center>

We can now subtract $c_{1}, c_{2} ... c_{k}$ from each of the sampled $x_{1}, x_{2} ... x_{k}$ and perform the OLS estimates on equation [6.30] where $\hat{\theta_{0}}$ is the intercept with an estimated standard error. Finding the standard error will lead us to defining the $t$-statistic based confidence interval.

::: {.task}
Task: Find the confidence interval for predicted college GPA (`wooldridge::gpa2`)
:::

1.  Compute the OLS for `colgpa ~ sat + hsperc + hsize + hsize^2`:

```{r}
data("gpa2", package = "wooldridge")
gpa2_dt <- data.table(
  colgpa = gpa2$colgpa,
  sat = gpa2$sat,
  hsperc = gpa2$hsperc,
  hsize = gpa2$hsize,
  hsize_sq = gpa2$hsize^2
)
gpa2_ols_lst <- RregressPkg::ols_calc(
  x = gpa2_dt,
  resp_col = "colgpa"
)
```

2.  Show the coefficients and their standard errors:

```{r}
RplotterPkg::create_table(x = gpa2_ols_lst$coef_df)
```

3.  Assign a specific set of values for the predictors (i.e. $c_{1}, c_{2} ... c_{k}$) and subtract these values from our sample predictors $x_{1}, x_{2} ... x_{k}$:

```{r}
gpa2_dt[, `:=`(sat_d = sat - 1200, hsperc_d = hsperc - 30, hsize_d = hsize - 5, hsize_sq_d = hsize_sq - 25)]
head(gpa2_dt)
```

4.  Re-compute the OLS estimate on the new set of predictor values:

```{r}
gpa2_new_dt <- data.table(
  colgpa = gpa2_dt$colgpa,
  sat = gpa2_dt$sat_d,
  hsperc = gpa2_dt$hsperc_d,
  hsize = gpa2_dt$hsize_d,
  hsize_sq = gpa2_dt$hsize_sq_d
)
gpa2_ols_new_lst <- RregressPkg::ols_calc(
  x = gpa2_new_dt,
  resp_col = "colgpa"
)
```

5.  Show the coefficients and their standard errors:

```{r}
RplotterPkg::create_table(x = gpa2_ols_new_lst$coef_df)
```

Note that there is no change in the coefficient values -- the only change is our intercept value and standard error which is the standard error for $\hat{\theta_{0}}$ -- our response variable from equation [6.29] above.

Now that we have the value for $\hat{\theta_{0}}$ (2.70) and its standard error (0.019) we can compute its $t$-statistic based confidence intervals.

6.  Compute $\hat{\theta_{0}}$ confidence intervals at the 95% confidence level:

```{r}
t_val <- stats::qt(0.975, gpa2_ols_new_lst$n -1)
CI_upper <- gpa2_ols_new_lst$coef[["Interc"]] + gpa2_ols_new_lst$coef_se[["Interc"]] * t_val
CI_lower <- gpa2_ols_new_lst$coef[["Interc"]] - gpa2_ols_new_lst$coef_se[["Interc"]] * t_val
```

The upper CI for $\hat{\theta_{0}}$ is `r CI_upper`

The lower CI for $\hat{\theta_{0}}$ is `r CI_lower`

::: {.task}
Task: Compare the above results with results using R's `stats::predict()`.
:::

1.  Compute the model using `stats::lm()`:

```{r}
gpa2_lm <- stats::lm(colgpa ~ sat + hsperc + hsize + I(hsize^2), data = gpa2)
gpa2_lm
```

2.  Compute point estimate prediction:

```{r}
c_values <- data.frame(sat = 1200, hsperc = 30, hsize = 5)
theta_0 <- stats::predict(gpa2_lm, c_values)
theta_0
```

3.  Compute confidence interval:

```{r}
ci_theta_0 <- stats::predict(gpa2_lm, c_values, interval = "confidence")
ci_theta_0
```

The two approaches agree.

### 6.2.2 Prediction Intervals

Confidence intervals reflect the uncertainty about the **expected value** of the response variable given values for the predictors. In predicting an **individual** we have to account for the additional uncertainty regarding the unobserved characteristics reflected by the error term $\mu$.

We now have two sources of variation:

a. The sampling error in estimating the predictor coefficients which we did in equation [6.29] above for $\hat{\theta_{0}}$

b. The variance of the error in the population $\mu$

<div class="task">Task: Use `RregressPkg::ols_predict_calc()` to estimate prediction intervals for the college gpa (`wooldridge::gpa2`).</div>

1. Set up the data:
```{r}
gpa_2_dt <- data.table::setDT(wooldridge::gpa2)
gpa_2_dt <- gpa_2_dt[, .(colgpa, sat, hsperc, hsize)]
gpa_2_dt[, hsize_sq := hsize^2]
```

2. Define the predictor data points to estimate responses:
```{r}
predictors_df <- data.frame(
  sat = c(1200, 900, 1400),
  hsperc = c(30, 20, 5),
  hsize = c(5, 3, 1),
  hsize_sq = c(25, 9, 1)
)
```

3. Call `RregressPkg::ols_predict_calc()`:
```{r}
gpa_2_response_df <- RregressPkg::ols_predict_calc(
  x = gpa_2_dt,
  interval = "confidence",
  confid_level = 0.99,
  resp_col = "colgpa",
  predictors_df = predictors_df
)
```

4. Display the results:
```{r}
RplotterPkg::create_table(gpa_2_response_df, caption = "College gpa Estimates")
```










